{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os,sys,inspect\n",
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "sys.path.insert(0, parentdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Apr 28 17:03:27 2019       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 418.56       Driver Version: 418.56       CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce GTX 1080    Off  | 00000000:02:00.0 Off |                  N/A |\n",
      "|  0%   35C    P2    37W / 198W |      2MiB /  8119MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from utils.utils import get_train, convert\n",
    "from utils.preprocess import preprocess_sentence, max_length, tokenize\n",
    "from models.encoder import Encoder\n",
    "from models.decoder import Decoder\n",
    "from models.bahdanauattention import BahdanauAttention\n",
    "from models.keyvalueattention import KeyValueAttention\n",
    "\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "import io\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0-alpha0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.61 s, sys: 398 ms, total: 2 s\n",
      "Wall time: 2.16 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = get_train(nrows=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>firstSentence</th>\n",
       "      <th>secondSentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;start&gt; you ' re not alone , claire . &lt;end&gt;</td>\n",
       "      <td>&lt;start&gt; you are not alone , claire . &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;start&gt; who told you to throw acid at vargas ,...</td>\n",
       "      <td>&lt;start&gt; who told you to throw acid at vargas ?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;start&gt; where the pure angel merges with the a...</td>\n",
       "      <td>&lt;start&gt; where the pure angel merges with the a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;start&gt; where is it written what is it i ' m m...</td>\n",
       "      <td>&lt;start&gt; where is it written what it is i ' m m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;start&gt; we ' ll find the skipper and then we '...</td>\n",
       "      <td>&lt;start&gt; we ' ll find the skipper and then we g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>&lt;start&gt; seymour ' s darling is third . . . and...</td>\n",
       "      <td>&lt;start&gt; seymour ' s darling is third . . . and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>&lt;start&gt; scud , do you read me ? &lt;end&gt;</td>\n",
       "      <td>&lt;start&gt; scud , you reading me ? &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>&lt;start&gt; jumby now wants to be born . &lt;end&gt;</td>\n",
       "      <td>&lt;start&gt; jumby want birth . &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>&lt;start&gt; it was a difficult and long delivery ....</td>\n",
       "      <td>&lt;start&gt; the delivery was difficult and long . ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>&lt;start&gt; it ' s a shit , but it ' s better than...</td>\n",
       "      <td>&lt;start&gt; it ' s a shit , but it ' s better that...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       firstSentence  \\\n",
       "0        <start> you ' re not alone , claire . <end>   \n",
       "1  <start> who told you to throw acid at vargas ,...   \n",
       "2  <start> where the pure angel merges with the a...   \n",
       "3  <start> where is it written what is it i ' m m...   \n",
       "4  <start> we ' ll find the skipper and then we '...   \n",
       "5  <start> seymour ' s darling is third . . . and...   \n",
       "6              <start> scud , do you read me ? <end>   \n",
       "7         <start> jumby now wants to be born . <end>   \n",
       "8  <start> it was a difficult and long delivery ....   \n",
       "9  <start> it ' s a shit , but it ' s better than...   \n",
       "\n",
       "                                      secondSentence  \n",
       "0         <start> you are not alone , claire . <end>  \n",
       "1  <start> who told you to throw acid at vargas ?...  \n",
       "2  <start> where the pure angel merges with the a...  \n",
       "3  <start> where is it written what it is i ' m m...  \n",
       "4  <start> we ' ll find the skipper and then we g...  \n",
       "5  <start> seymour ' s darling is third . . . and...  \n",
       "6              <start> scud , you reading me ? <end>  \n",
       "7                   <start> jumby want birth . <end>  \n",
       "8  <start> the delivery was difficult and long . ...  \n",
       "9  <start> it ' s a shit , but it ' s better that...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = df.copy()\n",
    "df_train['firstSentence'] = np.vectorize(preprocess_sentence)(df_train['firstSentence'])\n",
    "df_train['secondSentence'] = np.vectorize(preprocess_sentence)(df_train['secondSentence'])\n",
    "df_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 272 ms, sys: 328 Âµs, total: 272 ms\n",
      "Wall time: 275 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "input_tensor, inp_tokenizer = tokenize(df_train['firstSentence'].values.tolist())\n",
    "target_tensor, targ_tokenizer = tokenize(df_train['secondSentence'].values.tolist())\n",
    "max_length_targ, max_length_inp = max_length(target_tensor), max_length(input_tensor)\n",
    "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\n",
    "len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\t<start>\n",
      "20\the\n",
      "95\tdidn\n",
      "4\t'\n",
      "18\tt\n",
      "367\teven\n",
      "107\tsay\n",
      "928\tgoodbye\n",
      "3\t.\n",
      "2\t<end>\n",
      "1\t<start>\n",
      "143\tsorry\n",
      "8\t,\n",
      "49\twill\n",
      "3\t.\n",
      "2\t<end>\n"
     ]
    }
   ],
   "source": [
    "convert(inp_tokenizer, input_tensor_train[5])\n",
    "convert(targ_tokenizer, target_tensor_train[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([64, 26]), TensorShape([64, 27]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BUFFER_SIZE = len(input_tensor_train)\n",
    "BATCH_SIZE = 64\n",
    "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\n",
    "embedding_dim = 256\n",
    "units = 1024\n",
    "vocab_inp_size = len(inp_tokenizer.word_index)+1\n",
    "vocab_tar_size = len(targ_tokenizer.word_index)+1\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
    "example_input_batch, example_target_batch = next(iter(dataset))\n",
    "example_input_batch.shape, example_target_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inp, targ, enc_hidden):\n",
    "    loss = 0\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
    "\n",
    "        dec_hidden = enc_hidden\n",
    "\n",
    "        dec_input = tf.expand_dims([targ_tokenizer.word_index['<start>']] *\n",
    "                                   BATCH_SIZE, 1)\n",
    "\n",
    "        # Teacher forcing - feeding the target as the next input\n",
    "        for t in range(1, targ.shape[1]):\n",
    "            # passing enc_output to the decoder\n",
    "            predictions, dec_hidden, _ = decoder(dec_input, dec_hidden,\n",
    "                                                 enc_output)\n",
    "\n",
    "            loss += loss_function(targ[:, t], predictions)\n",
    "\n",
    "            # using teacher forcing\n",
    "            dec_input = tf.expand_dims(targ[:, t], 1)\n",
    "\n",
    "    batch_loss = (loss / int(targ.shape[1]))\n",
    "\n",
    "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "\n",
    "    gradients = tape.gradient(loss, variables)\n",
    "\n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "\n",
    "    return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder output shape: (batch size, sequence length, units) (64, 26, 1024)\n",
      "Encoder Hidden state shape: (batch size, units) (64, 1024)\n",
      "Attention result shape: (batch size, units) (64, 1024)\n",
      "Attention weights shape: (batch_size, sequence_length, 1) (64, 26, 1)\n",
      "Decoder output shape: (batch_size, vocab size) (64, 3264)\n"
     ]
    }
   ],
   "source": [
    "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
    "\n",
    "# sample input\n",
    "sample_hidden = encoder.initialize_hidden_state()\n",
    "sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n",
    "print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
    "print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))\n",
    "attention_layer = BahdanauAttention(10)\n",
    "attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n",
    "\n",
    "print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\n",
    "print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))\n",
    "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
    "\n",
    "sample_decoder_output, _, _ = decoder(tf.random.uniform((64, 1)),\n",
    "                                      sample_hidden, sample_output)\n",
    "\n",
    "print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_checkpoints_3'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer, encoder=encoder, decoder=decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 1.9105\n",
      "Epoch 1 Batch 100 Loss 0.8551\n",
      "Epoch 1 Loss 0.9933\n",
      "Time taken for 1 epoch 41.818681478500366 sec\n",
      "\n",
      "Epoch 2 Batch 0 Loss 0.8360\n",
      "Epoch 2 Batch 100 Loss 0.6933\n",
      "Epoch 2 Loss 0.7185\n",
      "Time taken for 1 epoch 22.642045259475708 sec\n",
      "\n",
      "Epoch 3 Batch 0 Loss 0.6773\n",
      "Epoch 3 Batch 100 Loss 0.5879\n",
      "Epoch 3 Loss 0.6015\n",
      "Time taken for 1 epoch 22.469702005386353 sec\n",
      "\n",
      "Epoch 4 Batch 0 Loss 0.5917\n",
      "Epoch 4 Batch 100 Loss 0.4939\n",
      "Epoch 4 Loss 0.5153\n",
      "Time taken for 1 epoch 22.62120246887207 sec\n",
      "\n",
      "Epoch 5 Batch 0 Loss 0.5088\n",
      "Epoch 5 Batch 100 Loss 0.4149\n",
      "Epoch 5 Loss 0.4386\n",
      "Time taken for 1 epoch 22.43719506263733 sec\n",
      "\n",
      "Epoch 6 Batch 0 Loss 0.4273\n",
      "Epoch 6 Batch 100 Loss 0.3515\n",
      "Epoch 6 Loss 0.3731\n",
      "Time taken for 1 epoch 22.721723079681396 sec\n",
      "\n",
      "Epoch 7 Batch 0 Loss 0.3596\n",
      "Epoch 7 Batch 100 Loss 0.2819\n",
      "Epoch 7 Loss 0.3118\n",
      "Time taken for 1 epoch 22.559738159179688 sec\n",
      "\n",
      "Epoch 8 Batch 0 Loss 0.2918\n",
      "Epoch 8 Batch 100 Loss 0.2309\n",
      "Epoch 8 Loss 0.2523\n",
      "Time taken for 1 epoch 22.745192050933838 sec\n",
      "\n",
      "Epoch 9 Batch 0 Loss 0.2320\n",
      "Epoch 9 Batch 100 Loss 0.2089\n",
      "Epoch 9 Loss 0.2032\n",
      "Time taken for 1 epoch 22.630247354507446 sec\n",
      "\n",
      "Epoch 10 Batch 0 Loss 0.1887\n",
      "Epoch 10 Batch 100 Loss 0.1348\n",
      "Epoch 10 Loss 0.1606\n",
      "Time taken for 1 epoch 22.88136053085327 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "\n",
    "    enc_hidden = encoder.initialize_hidden_state()\n",
    "    total_loss = 0\n",
    "\n",
    "    for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
    "        batch_loss = train_step(inp, targ, enc_hidden)\n",
    "        total_loss += batch_loss\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            print('Epoch {} Batch {} Loss {:.4f}'.format(\n",
    "                epoch + 1, batch, batch_loss.numpy()))\n",
    "    # saving (checkpoint) the model every 2 epochs\n",
    "    if (epoch + 1) % 2 == 0:\n",
    "        checkpoint.save(file_prefix=checkpoint_prefix)\n",
    "\n",
    "    print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                        total_loss / steps_per_epoch))\n",
    "    print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(sentence):\n",
    "    attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
    "\n",
    "    sentence = preprocess_sentence(sentence)\n",
    "\n",
    "    inputs = [inp_tokenizer.word_index[i] for i in sentence.split(' ') if i in inp_tokenizer.word_index]\n",
    "    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
    "                                                           maxlen=max_length_inp,\n",
    "                                                           padding='post')\n",
    "    \n",
    "    inputs = tf.convert_to_tensor(inputs)\n",
    "\n",
    "    result = ''\n",
    "\n",
    "    hidden = [tf.zeros((1, units))]\n",
    "    enc_out, enc_hidden = encoder(inputs, hidden)\n",
    "\n",
    "    dec_hidden = enc_hidden\n",
    "    dec_input = tf.expand_dims([targ_tokenizer.word_index['<start>']], 0)\n",
    "\n",
    "    for t in range(max_length_targ):\n",
    "        predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
    "                                                             dec_hidden,\n",
    "                                                             enc_out)\n",
    "\n",
    "        # storing the attention weights to plot later on\n",
    "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "        attention_plot[t] = attention_weights.numpy()\n",
    "\n",
    "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "\n",
    "        \n",
    "        result += targ_tokenizer.index_word[predicted_id] + ' '\n",
    "\n",
    "        if targ_tokenizer.index_word[predicted_id] == '<end>':\n",
    "            return result, sentence, attention_plot\n",
    "\n",
    "        # the predicted ID is fed back into the model\n",
    "        dec_input = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "    return result, sentence, attention_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for plotting the attention weights\n",
    "def plot_attention(attention, sentence, predicted_sentence):\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.matshow(attention, cmap='viridis')\n",
    "\n",
    "    fontdict = {'fontsize': 14}\n",
    "\n",
    "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
    "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def re_parapharse(sentence):\n",
    "    result, sentence, attention_plot = evaluate(sentence)\n",
    "\n",
    "    print('Input: %s' % (sentence))\n",
    "    print('Predicted re_parapharse: {}'.format(result))\n",
    "\n",
    "    attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
    "    plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fb2ff619dd8>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>firstSentence</th>\n",
       "      <th>secondSentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9990</th>\n",
       "      <td>Look at the bright side .</td>\n",
       "      <td>Look on the bright side .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9991</th>\n",
       "      <td>Khaleesi .</td>\n",
       "      <td>Oh , Khaleesi .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9992</th>\n",
       "      <td>Shall we continue ?</td>\n",
       "      <td>Shall we go on ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9993</th>\n",
       "      <td>I 've already got a job .</td>\n",
       "      <td>I already got a job .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9994</th>\n",
       "      <td>Bag .</td>\n",
       "      <td>The bag .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>What are we gonna do with him ?</td>\n",
       "      <td>What do we do with him ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>Are you back ?</td>\n",
       "      <td>You came back ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>Yeah , I 've noticed .</td>\n",
       "      <td>Yeah , I noticed .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>What 's for dinner ?</td>\n",
       "      <td>What 's for supper ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>Where 's Dad ?</td>\n",
       "      <td>Where is dad ?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        firstSentence             secondSentence\n",
       "9990        Look at the bright side .  Look on the bright side .\n",
       "9991                       Khaleesi .            Oh , Khaleesi .\n",
       "9992              Shall we continue ?           Shall we go on ?\n",
       "9993        I 've already got a job .      I already got a job .\n",
       "9994                            Bag .                  The bag .\n",
       "9995  What are we gonna do with him ?   What do we do with him ?\n",
       "9996                   Are you back ?            You came back ?\n",
       "9997           Yeah , I 've noticed .         Yeah , I noticed .\n",
       "9998             What 's for dinner ?       What 's for supper ?\n",
       "9999                   Where 's Dad ?             Where is dad ?"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in df.iloc[2000:2010, :].firstSentence.values:\n",
    "    try:\n",
    "        re_parapharse(x)\n",
    "    except Exception as e:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate import bleu\n",
    "from nltk.translate.bleu_score import SmoothingFunction\n",
    "def test_blue(expected, candidate):\n",
    "    candidate = candidate.split(' ')\n",
    "    expected = expected.split(' ')\n",
    "    reference = [expected]\n",
    "    smoothie = SmoothingFunction().method4\n",
    "    return bleu([expected], candidate, smoothing_function=smoothie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input_text = df.iloc[4900:5000, :].firstSentence.values\n",
    "test_output_text = df.iloc[4900:5000, :].secondSentence.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25899290381849804\n",
      "<start> 5 , 000 . <end>\n",
      "two thousand . \n",
      "Five thousand .\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.27759395109587814"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blues = []\n",
    "for i in range(100):\n",
    "    result, sentence, attention_plot = evaluate(test_input_text[i])\n",
    "    new_result = result.replace('<start> ', '').replace(' <end>', '')\n",
    "    new_sentence = sentence.replace('<start> ', '').replace(' <end>', '')\n",
    "    blue = test_blue(test_output_text[i], new_result)\n",
    "    blues.append(blue)\n",
    "    if i == 81:\n",
    "        print(blue)\n",
    "        print(sentence)\n",
    "        print(new_result)\n",
    "        print(test_output_text[i])\n",
    "        plot_attention(attention_plot, sentence.split(' '), result.split(' '))\n",
    "np.average(blues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27.759395109587814"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.average(blues) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(blues) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75.98356856515926"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(blues)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.2941299913461552,\n",
       " 0.28650723815426243,\n",
       " 0.23796564142073365,\n",
       " 0.20798131143120685,\n",
       " 0.18665471083173696,\n",
       " 0.2875833792374545,\n",
       " 0.23640501160890146,\n",
       " 0.26335227287021584,\n",
       " 0.3655552228545123,\n",
       " 0.15948194035504248,\n",
       " 0.35772459775085663,\n",
       " 0.13374394457703614,\n",
       " 0.3655552228545123,\n",
       " 0.09673068649579478,\n",
       " 0.23016915699647844,\n",
       " 0.27727758246450607,\n",
       " 0.19879212680993805,\n",
       " 0.26762649011537704,\n",
       " 0.19817632389021378,\n",
       " 0.26762649011537704,\n",
       " 0.5081327481546147,\n",
       " 0.32756475929865714,\n",
       " 0.19879212680993805,\n",
       " 0.2450324327954738,\n",
       " 0.19879212680993805,\n",
       " 0.20170387630378334,\n",
       " 0.23016915699647844,\n",
       " 0.18665471083173696,\n",
       " 0.23728353900810106,\n",
       " 0.2984745896009823,\n",
       " 0.35772459775085663,\n",
       " 0.23681572145316945,\n",
       " 0.23016915699647844,\n",
       " 0.30483335667394,\n",
       " 0.25899290381849804,\n",
       " 0.26762649011537704,\n",
       " 0.19473925601061473,\n",
       " 0.18665471083173696,\n",
       " 0.668740304976422,\n",
       " 0.23640501160890146,\n",
       " 0.26335227287021584,\n",
       " 0.35772459775085663,\n",
       " 0.23796564142073365,\n",
       " 0.2450324327954738,\n",
       " 0.35772459775085663,\n",
       " 0.2450324327954738,\n",
       " 0.23978996883243478,\n",
       " 0.32756475929865714,\n",
       " 0.4410504175474598,\n",
       " 0.18742104002478158,\n",
       " 0.32756475929865714,\n",
       " 0.18665471083173696,\n",
       " 0.23728353900810106,\n",
       " 0.23796564142073365,\n",
       " 0.2326589746035907,\n",
       " 0.5873949094699213,\n",
       " 0.2450324327954738,\n",
       " 0.5081327481546147,\n",
       " 0.5081327481546147,\n",
       " 0.21780640299346554,\n",
       " 0.18665471083173696,\n",
       " 0.26335227287021584,\n",
       " 0.19473925601061473,\n",
       " 0.30483335667394,\n",
       " 0.6147881529512643,\n",
       " 0.29430004544273397,\n",
       " 0.19879212680993805,\n",
       " 0.6065306597126334,\n",
       " 0.3026643726685863,\n",
       " 0.35772459775085663,\n",
       " 0.23681572145316945,\n",
       " 0.15948194035504248,\n",
       " 0.345720784641941,\n",
       " 0.23681572145316945,\n",
       " 0.25899290381849804,\n",
       " 0.28650723815426243,\n",
       " 0.20170387630378334,\n",
       " 0.6065306597126334,\n",
       " 0.6803749333171202,\n",
       " 0.23640501160890146,\n",
       " 0.23796564142073365,\n",
       " 0.19564209772076444,\n",
       " 0.32756475929865714,\n",
       " 0.15948194035504248,\n",
       " 0.15948194035504248,\n",
       " 0.41113361690051975,\n",
       " 0.30483335667394,\n",
       " 0.30483335667394,\n",
       " 0.18665471083173696,\n",
       " 0.22141179722338475,\n",
       " 0.19953087735062713,\n",
       " 0.18665471083173696,\n",
       " 0.27727758246450607,\n",
       " 0.2326589746035907,\n",
       " 0.2875833792374545,\n",
       " 0.7788007830714049,\n",
       " 0.15236621890666366,\n",
       " 0.5247357977607321,\n",
       " 0.19913749124569236,\n",
       " 0.2152959298672331]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def demo(text):\n",
    "    test = preprocess_sentence(text)\n",
    "    result, sentence, attention_plot = evaluate(test)\n",
    "    print('input:', text)\n",
    "    print('predict:', result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: You'll never walk alone\n",
      "predict: you ' ll get me here . <end> \n"
     ]
    }
   ],
   "source": [
    "demo(\"You'll never walk alone\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: You're not alone\n",
      "predict: you ' re not alone . <end> \n"
     ]
    }
   ],
   "source": [
    "demo(\"You're not alone\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: I 've already got a job .\t\n",
      "predict: i ' m a little work . <end> \n"
     ]
    }
   ],
   "source": [
    "demo(\"I 've already got a job .\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: It was a difficult and long delivery .\n",
      "predict: it was just a matter of death . <end> \n"
     ]
    }
   ],
   "source": [
    "demo(\"It was a difficult and long delivery .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
